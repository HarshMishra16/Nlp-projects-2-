ğŸŒŸ Zero-Shot Text Classification Using Hugging Face Transformers
ğŸ“Œ NLP Assignment â€” Project 2

Submitted by: Harsh Kumar

ğŸ“– Project Overview

This project demonstrates Zero-Shot Text Classification using the Hugging Face Transformers library.
Zero-shot learning allows a model to classify text without training on the specific categories, making it extremely powerful for:

Topic Classification

Intent Detection

Content Categorization

Quick NLP Prototyping

This project uses the facebook/bart-large-mnli model, one of the most widely used models for zero-shot tasks.

ğŸ§  Objectives

âœ” Understand Zero-Shot Classification
âœ” Use the pipeline() API from Hugging Face
âœ” Provide a text input and custom labels
âœ” Allow the model to classify without training
âœ” View prediction labels & confidence scores

ğŸŒ What Is Zero-Shot Classification?

In zero-shot classification, the model uses natural language inference (NLI) to decide how well a given label fits the textâ€”
even if it has never been trained on those labels.

Example:
Input: â€œI want to learn deep learning and neural networks.â€
Candidate labels: ["education", "sports", "technology"]
Model will infer which label fits best.

ğŸ—‚ï¸ Project Structure
ğŸ“ ZeroShot-Classification/
â”‚â”€â”€ zero_shot_classifier.ipynb   # Main notebook/script
â”‚â”€â”€ README.md                    # Documentation

ğŸ“¦ Install Dependencies

Run in Google Colab or Terminal:

pip install transformers accelerate -q

ğŸ§© Code Used in This Project
ğŸ”¹ Import Pipeline
from transformers import pipeline

ğŸ”¹ Load Zero-Shot Classification Model
classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli"
)

ğŸ”¹ Input Text and Labels
text = "I want to learn deep learning and neural networks."

candidate_labels = ["education", "sports", "technology", "politics"]

ğŸ”¹ Run Classifier
result = classifier(text, candidate_labels)
result

ğŸ”¹ Print Final Predictions
print("Text:", result["sequence"])
print("\nPredictions:")
for label, score in zip(result["labels"], result["scores"]):
    print(f"{label}: {score:.4f}")

ğŸ“Š Sample Output
Text: I want to learn deep learning and neural networks.

Predictions:
education: 0.8521
technology: 0.1472
politics: 0.0003
sports: 0.0002

ğŸ Key Features of This Project

âœ” No need to train a model
âœ” Works with any label you give
âœ” BART MNLI provides strong zero-shot accuracy
âœ” Simple, fast, and ideal for experimentation

ğŸš€ Possible Extensions

Add multiple sentences for batch classification

Compare BART with RoBERTa MNLI

Deploy the pipeline using FastAPI

Convert the script into a function-based Python module

ğŸ‰ Conclusion

This project showcases how easy and powerful Zero-Shot Classification can be using Hugging Face Transformers.
It helps classify any text into any custom categories without training â€” making it perfect for real-world NLP applications.
